include required("reference.conf")

# NOTE: this file should contain deviations from the standard ("production default") reference.conf for use
# in the Test context
# Typelevel Config loads application-test.conf first and if it doesn't find it, reference.conf
# Our own TypeHelper will look for application-test.conf first.

extraListeners = com.hortonworks.spark.atlas.SparkAtlasEventTracker
sql.queryExecutionListeners = com.hortonworks.spark.atlas.SparkAtlasEventTracker

archive = true

file-system = "file://"

hive = false

grouped = true

analyze = false

encryption-types {
  "PAN" : 50,
  "IBAN": 50
}

jdbc = {
  "test-h2": {
    engine = "h2"

    ## The default URI is in memory only
    uri = "jdbc:h2:mem:test-"${COMET_TEST_ID}";DB_CLOSE_DELAY=-1",

    ## uncomment this in order to have traces (on the console) about the in-flight SQL
    # uri = "jdbc:h2:mem:test-"${COMET_TEST_ID}";DB_CLOSE_DELAY=-1;TRACE_LEVEL_SYSTEM_OUT=2",

    ## Uncomment the following to keep an on-disk trace of your test database:
    # uri = "jdbc:h2:/tmp/h2-"${COMET_TEST_ID}"",

    user="sa"
    password="sa"
  }
}

audit {
  index {
    type = "None" // By default
    jdbc-connection = "test-h2"
    # bq-dataset = "audit"
  }
}

metrics {
  active = true
  index {
    type = "None" // By default
    jdbc-connection = "test-h2"
    # bq-dataset = "audit"
  }
}

spark {
  debug.maxToStringFields=100
  master = "local[*]"
}
